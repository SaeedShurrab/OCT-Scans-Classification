{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "from torchvision.transforms import Compose, ToTensor, Lambda\n",
    "from torchvision.transforms import Resize, Normalize\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm import tqdm\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random seed setting\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data directories initiation\n",
    "train_data_dir = os.path.join(os.curdir,'..','..','data','preprocessed','classification','train')\n",
    "val_data_dir = os.path.join(os.curdir,'..','..','data','preprocessed','classification','val')\n",
    "weights_path = os.path.join(os.curdir,'..','..','models','Autoencoder-weights','resnet18.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.block = nn.Sequential(\n",
    "                nn.Conv2d(**kwargs),\n",
    "                nn.BatchNorm2d(num_features=kwargs['out_channels']),       \n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.block(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels, stride = 1,downsample = False):\n",
    "        super(ResBlock,self).__init__()\n",
    "        \n",
    "        self.block1 = ConvBlock(in_channels= in_channels,out_channels= out_channels, stride= stride,\n",
    "                                kernel_size=3, padding = 1, bias= False)\n",
    "        self.block2 = ConvBlock(in_channels= out_channels,out_channels= out_channels, stride= 1,\n",
    "                               kernel_size= 3,padding = 1, bias = False)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        if downsample:\n",
    "            self.downsample = ConvBlock(in_channels=in_channels,out_channels= out_channels,\n",
    "                                        kernel_size= 1, stride= 2, bias= False )\n",
    "        else:\n",
    "            self.downsample = None\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.block1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.block2(x)\n",
    "        \n",
    "        if self.downsample != None:\n",
    "            identity = self.downsample(identity)\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AEResnet(nn.Module):\n",
    "    def __init__(self, output_dim=2, res34=False,):\n",
    "        super(AEResnet,self).__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.res34 = res34\n",
    "        self.same_layer = nn.MaxPool2d(kernel_size=1,stride=1)\n",
    "        \n",
    "        \n",
    "        #Encoder\n",
    "        self.conv1 = ConvBlock(in_channels= 3, out_channels= 64, kernel_size= 7,\n",
    "                        stride= 2, padding= 3, bias= False) \n",
    "\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size= 3, stride= 2, padding=1)\n",
    "        self.relu = nn.ReLU(inplace= True)\n",
    "        \n",
    "        \n",
    "        self.conv2_x = nn.Sequential(\n",
    "                ResBlock(in_channels=64, out_channels=64, stride=1, downsample=False),\n",
    "                ResBlock(in_channels=64, out_channels=64, stride=1, downsample=False),\n",
    "                ResBlock(in_channels=64, out_channels=64, stride=1, downsample=False) \n",
    "                        if self.res34 else self.same_layer\n",
    "        \n",
    "        ) \n",
    "        self.conv3_x = nn.Sequential(\n",
    "                ResBlock(in_channels=64, out_channels=128, stride=2, downsample=True),\n",
    "                ResBlock(in_channels=128, out_channels=128, stride=1, downsample=False),\n",
    "                ResBlock(in_channels=128, out_channels=128, stride=1, downsample=False) \n",
    "                        if self.res34 else self.same_layer,\n",
    "                ResBlock(in_channels=128, out_channels=128, stride=1, downsample=False) \n",
    "                        if self.res34 else self.same_layer,\n",
    "        )\n",
    "        \n",
    "        self.conv4_x = nn.Sequential(\n",
    "                ResBlock(in_channels=128, out_channels=256, stride=2, downsample=True),\n",
    "                ResBlock(in_channels=256, out_channels=256, stride=1, downsample=False),\n",
    "                ResBlock(in_channels=256, out_channels=256, stride=1, downsample=False) \n",
    "                        if self.res34 else self.same_layer,\n",
    "                ResBlock(in_channels=256, out_channels=256, stride=1, downsample=False) \n",
    "                        if self.res34 else self.same_layer,\n",
    "                ResBlock(in_channels=256, out_channels=256, stride=1, downsample=False) \n",
    "                        if self.res34 else self.same_layer,\n",
    "                ResBlock(in_channels=256, out_channels=256, stride=1, downsample=False) \n",
    "                        if self.res34 else self.same_layer,\n",
    "        )\n",
    "\n",
    "        self.conv5_x = nn.Sequential(\n",
    "                ResBlock(in_channels=256, out_channels=512, stride=2, downsample=True),\n",
    "                ResBlock(in_channels=512, out_channels=512, stride=1, downsample=False),\n",
    "                ResBlock(in_channels=512, out_channels=512, stride=1, downsample=False) \n",
    "                        if self.res34 else self.same_layer\n",
    "        \n",
    "        ) \n",
    "               \n",
    "        \n",
    "\n",
    "        \n",
    "        self.avg_pooling = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "        self.fc = nn.Linear(512,self.output_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.conv2_x(x)\n",
    "        x = self.conv3_x(x)\n",
    "        x = self.conv4_x(x)\n",
    "        x = self.conv5_x(x)\n",
    "        x = self.avg_pooling(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the pretrained model\n",
    "model = AEResnet(output_dim=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['fc.weight', 'fc.bias'], unexpected_keys=['block6.0.block.0.weight', 'block6.0.block.0.bias', 'block6.0.block.1.weight', 'block6.0.block.1.bias', 'block6.0.block.1.running_mean', 'block6.0.block.1.running_var', 'block6.0.block.1.num_batches_tracked', 'block6.1.block.0.weight', 'block6.1.block.0.bias', 'block6.1.block.1.weight', 'block6.1.block.1.bias', 'block6.1.block.1.running_mean', 'block6.1.block.1.running_var', 'block6.1.block.1.num_batches_tracked', 'block6.2.block.0.weight', 'block6.2.block.0.bias', 'block6.2.block.1.weight', 'block6.2.block.1.bias', 'block6.2.block.1.running_mean', 'block6.2.block.1.running_var', 'block6.2.block.1.num_batches_tracked', 'block6.3.block.0.weight', 'block6.3.block.0.bias', 'block6.3.block.1.weight', 'block6.3.block.1.bias', 'block6.3.block.1.running_mean', 'block6.3.block.1.running_var', 'block6.3.block.1.num_batches_tracked', 'block6.4.block.0.weight', 'block6.4.block.0.bias', 'block6.4.block.1.weight', 'block6.4.block.1.bias', 'block6.4.block.1.running_mean', 'block6.4.block.1.running_var', 'block6.4.block.1.num_batches_tracked'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu')),strict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification layer defination\n",
    "INPUT_DIM = model.fc.in_features\n",
    "OUTPUT_DIM = model.fc.out_features\n",
    "\n",
    "FC_layer = nn.Linear(INPUT_DIM,OUTPUT_DIM)\n",
    "model.fc = FC_layer\n",
    "model.fc.weight.requires_grad = True\n",
    "model.fc.bias.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weieghts freezing\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 11,178,564 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729096996/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/opt/conda/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    }
   ],
   "source": [
    "#hyperparametres and setting\n",
    "lr = 0.001\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "weight_decay=0\n",
    "optimizer = optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "schedular = optim.lr_scheduler.StepLR(optimizer, gamma=0.5,step_size=3,verbose=True)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# related transformation defination\n",
    "ROCT_MEANS = [0.20041628,0.20041628,0.20041628]\n",
    "ROCT_STDEVS = [0.20288454,0.20288454,0.20288454]\n",
    "\n",
    "\n",
    "\n",
    "transforms = Compose([\n",
    "                    Resize(224),\n",
    "                    Lambda(lambda x: x.convert('RGB')),\n",
    "                    ToTensor(),\n",
    "                    Normalize(ROCT_MEANS,ROCT_STDEVS)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and labeling\n",
    "train_data = ImageFolder(root= train_data_dir,\n",
    "                         transform= transforms,\n",
    "                         )\n",
    "\n",
    "val_data = ImageFolder(root= val_data_dir,\n",
    "                       transform= transforms,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data classes:  {'CNV': 0, 'DME': 1, 'DRUSEN': 2, 'NORMAL': 3} \n",
      "\n",
      "Valid. data classes:  {'CNV': 0, 'DME': 1, 'DRUSEN': 2, 'NORMAL': 3}\n"
     ]
    }
   ],
   "source": [
    "print('Train data classes: ', train_data.class_to_idx,'\\n')\n",
    "print('Valid. data classes: ', val_data.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data iterator defination\n",
    "\n",
    "\n",
    "train_iterator = DataLoader(train_data,\n",
    "                            shuffle = True,\n",
    "                            batch_size=batch_size)\n",
    "\n",
    "val_iterator = DataLoader(val_data,\n",
    "                          shuffle = True,\n",
    "                          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device,schedular ,scaler= False):\n",
    "    print('training')\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for (image, label) in tqdm(iterator):\n",
    "        \n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if scaler:\n",
    "            \n",
    "            with torch.cuda.amp.autocast():     \n",
    "                \n",
    "                label_pred = model(image)\n",
    "                loss = criterion(label_pred, label)\n",
    "                assert label_pred.dtype is torch.float16\n",
    "                \n",
    "        else:\n",
    "            label_pred = model(image)\n",
    "            loss = criterion(label_pred, label)\n",
    "        \n",
    "        acc = calculate_accuracy(label_pred, label)\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "        if scaler:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        \n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "    schedular.step()\n",
    "\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device):\n",
    "    print('validating')\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for (image, label) in tqdm(iterator):\n",
    "\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            label_pred = model(image)\n",
    "\n",
    "            loss = criterion(label_pred, label)\n",
    "\n",
    "            acc = calculate_accuracy(label_pred, label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = criterion.to(device)\n",
    "best_valid_loss = float('inf')\n",
    "model_name = 'AEpretrained_resnet18_weights'\n",
    "log = pd.DataFrame(columns=['train_loss','train_acc' ,'val_loss', 'val_acc'])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    start_time = time.monotonic()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion,device,schedular,scaler=False)\n",
    "    val_loss, val_acc = evaluate(model, val_iterator, criterion, device)\n",
    "        \n",
    "    if val_loss < best_valid_loss:\n",
    "        best_valid_loss = val_loss\n",
    "        torch.save(model.state_dict(), model_name)\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    log.loc[len(log.index)] = [train_loss,train_acc,val_loss,val_acc]\n",
    "    log.to_csv('log.csv')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s, current time: {time.ctime()}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
